# -*- coding: utf-8 -*-
"""Very Large Dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kl_mKuRLofb7J7yTkNbjdJ6ViY3c3v1z

# **Performing K-Fold Validation and Holdout Validation on Large Dataset with Multiclass Classification**

## We will build a model that predicts what types of trees grow in an area based on the surrounding characteristics and evaluate that model with K-Fold validation and Holdout Validation to generate insights
"""

# import all necessary libraries

from timeit import default_timer as timer
import numpy as np
import matplotlib
from matplotlib import pyplot as plt
import pandas as pd
import seaborn as sns
from sklearn import datasets, linear_model, metrics
from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score
from sklearn.metrics import confusion_matrix
from sklearn.utils.multiclass import unique_labels

# upload dataset from kaggle

from google.colab import files
uploaded = files.upload()

# initialize data frame

df = pd.read_csv("covtype.csv")
df.head()

# check the type of our Y variable to avoid future imputations

df['Cover_Type'].dtype

df.tail()

# that's a lot of rows!

# notice that we use all features of our dataset so that we can illustrate how taxing cross validation will be

X=df.loc[:,'Elevation':'Soil_Type40']
y=df['Cover_Type']

# some nan values happen to sneak into our dataset so we will fill them up

X = X.fillna(method='ffill')
y = y.fillna(method='ffill')

"""## Initialize our ML algorithm"""

# use a K-nearest neighbhors machine learning algorithm

neigh = KNeighborsClassifier(n_neighbors=5)

"""## **K-Fold Validation**"""

# only with 200 folds are we able to generate an accuracy of 80%

neigh.fit(X,y)
kFoldStart = time.time()
y_pred = cross_val_predict(neigh, X, y, cv = 200)
kFoldEnd = time.time()
kFoldTime = kFoldEnd - kFoldStart
print("K Fold Validation Accuracy is ", accuracy_score(y, y_pred))

# it takes 16 minutes to run the K-Fold cross validation!!!!

print(kFoldTime)

# generate a heatmap of a confusion matrix with predicted and true values of the type of trees

labels = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0]
cm = confusion_matrix(y_pred, y, labels)
print(cm)
fig = plt.figure()
ax = fig.add_subplot(111)
cax = ax.matshow(cm, vmin=0, vmax=19000)
fig.colorbar(cax)
ax.set_xticklabels([''] + labels)
ax.set_yticklabels([''] + labels)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

"""## **Holdout Validation**"""

# split our dataset into training and testing data

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=101)

# some nan values happen to sneak into our dataset so we will fill them up

X_train = X_train.fillna(method='ffill')
y_train = y_train.fillna(method='ffill')

# run the holdout validation and make predictions
# it takes only 30 seconds for a normal validation which is still pretty long

neigh.fit(X_train, y_train)
holdOutStart = time.time()
holdOutPredictions = neigh.predict(X_test)
holdOutEnd = time.time()
holdOutTime = holdOutEnd - holdOutStart
print("Hold Out Validation takes ", holdOutTime, " seconds")

print(accuracy_score(y_test, holdOutPredictions))

# notice how much more accurate the holdout validation is compared to the k-fold cross validation

# generate a heatmap of a confusion matrix with predicted and true values of the type of trees

labels = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0]
cm = confusion_matrix(holdOutPredictions, y_test, labels)
print(cm)
fig = plt.figure()
ax = fig.add_subplot(111)
cax = ax.matshow(cm, vmin=0, vmax=8000)
fig.colorbar(cax)
ax.set_xticklabels([''] + labels)
ax.set_yticklabels([''] + labels)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()